{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#AdaBoost-类\" data-toc-modified-id=\"AdaBoost-类-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>AdaBoost 类</a></span><ul class=\"toc-item\"><li><span><a href=\"#基础分类器\" data-toc-modified-id=\"基础分类器-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>基础分类器</a></span></li><li><span><a href=\"#验证\" data-toc-modified-id=\"验证-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>验证</a></span></li><li><span><a href=\"#使用鸢尾花数据集进行测试\" data-toc-modified-id=\"使用鸢尾花数据集进行测试-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>使用鸢尾花数据集进行测试</a></span></li><li><span><a href=\"#sklearn.AdaBoostClassifier\" data-toc-modified-id=\"sklearn.AdaBoostClassifier-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>sklearn.AdaBoostClassifier</a></span></li></ul></li><li><span><a href=\"#提升树模型\" data-toc-modified-id=\"提升树模型-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>提升树模型</a></span><ul class=\"toc-item\"><li><span><a href=\"#使用-sklearn.ensemble.AdaBoostRegressor\" data-toc-modified-id=\"使用-sklearn.ensemble.AdaBoostRegressor-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>使用 sklearn.ensemble.AdaBoostRegressor</a></span></li><li><span><a href=\"#使用-sklearn.ensemble.GradientBoostingRegressor\" data-toc-modified-id=\"使用-sklearn.ensemble.GradientBoostingRegressor-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>使用 sklearn.ensemble.GradientBoostingRegressor</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](boosting.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天的主题是**集成学习**中的$adaboost$, 或称作$adaptive \\ boosting$, 首先我们来建立一种概念, 什么是$adaptive \\ boosting$:\n",
    "$adaboost$是**集成学习**的一种, 意思是建立多个**弱分类器**, 然后用这些弱分类器的**线性加权组合**来形成一个**强分类器**. 什么是弱分类器呢, 就是只比胡猜稍微好一点的分类器, 训练这些弱分类器是一个迭代的过程, 在这个过程里, 下一个弱分类器总是更加关注上一个弱分类器没有分好的数据样本, 以弥补之前弱分类器的不足, $adaboost$就是类似\"三个臭皮匠顶个诸葛亮\"的算法.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, base):\n",
    "        self.base = base # 弱分类器\n",
    "    \n",
    "    def fit(self, X, Y, max_step):\n",
    "        N = len(X)\n",
    "        self.W = np.ones(N) / N # 每个样本的权值初始化\n",
    "        self.alpha = [] # 存放弱分类器权重\n",
    "        self.weaker = [] # 存放弱分类器\n",
    "        for step in range(max_step): # 训练弱分类器\n",
    "            weaker = copy.deepcopy(self.base) # 生成一个新弱分类器\n",
    "            weaker.fit(X, Y, sample_weight = self.W) # 使用弱分类器带样本权值进行训练\n",
    "            results = weaker.predict(X)\n",
    "            # 输出准确度（Accuracy）\n",
    "            scores = (results == Y)\n",
    "            print('Weaker {:} accuracy = {:3.2f}%'.format(step, Counter(scores)[True]/len(Y) * 100))\n",
    "            # 计算当前弱分类器的分类误差率：带权值误差\n",
    "            error = np.dot(self.W, [0 if score else 1 for score in scores])\n",
    "            alpha = 0.5 * np.log((1 - error)/error) # 计算当前弱分类器的权重\n",
    "            self.alpha.append(alpha)\n",
    "            self.W = self.W * np.exp(alpha * np.array([-1 if score else 1 for score in scores])) # 更新每个样本的权值：分类正确-yG(x)=-1，否则 1\n",
    "            self.W = self.W / sum(self.W) # 归一化\n",
    "            self.weaker.append(weaker)\n",
    "        # 计算最终分类器的结果\n",
    "        f = np.dot(np.c_[[weaker.predict(X) for weaker in self.weaker]].T, np.array(self.alpha).reshape(-1, 1))\n",
    "        results = [1 if y >= 0 else -1 for y in f]\n",
    "        scores = (results == Y)\n",
    "        print('\\nAdaBoost accuracy = {:3.2f}%, training completed!'.format(Counter(scores)[True]/len(Y) * 100))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        f = np.dot(np.c_[[weaker.predict(X) for weaker in self.weaker]].T, np.array(self.alpha).reshape(-1, 1))\n",
    "        return [1 if y >= 0 else -1 for y in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple: \n",
    "    def fit(self, X, Y, sample_weight):\n",
    "        minloss = float('inf')\n",
    "        for compare in [operator.le, operator.ge]:\n",
    "            for threshold in X:\n",
    "                results = compare(np.array(X), threshold)\n",
    "                results = [1 if result else -1 for result in results]\n",
    "                results = results == Y\n",
    "                results = [0 if result else 1 for result in results]\n",
    "                loss = np.dot(results, sample_weight)\n",
    "                if minloss > loss:\n",
    "                    minloss = loss\n",
    "                    self.threshold = threshold\n",
    "                    self.compare = compare\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return [1 if self.compare(x, self.threshold) else -1 for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "Y = [1, 1, 1, -1, -1, -1, 1, 1, 1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaker 0 accuracy = 70.00%\n",
      "Weaker 1 accuracy = 70.00%\n",
      "Weaker 2 accuracy = 60.00%\n",
      "\n",
      "AdaBoost accuracy = 100.00%, training completed!\n",
      "[0.4236489301936017, 0.6496414920651304, 0.752038698388137]\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoost(Simple())\n",
    "ada.fit(np.array(X), np.array(Y), 3)\n",
    "print(ada.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaker 0 accuracy = 70.00%\n",
      "Weaker 1 accuracy = 70.00%\n",
      "Weaker 2 accuracy = 60.00%\n",
      "\n",
      "AdaBoost accuracy = 100.00%, training completed!\n",
      "[0.4236489301936017, 0.6496414920651304, 0.752038698388137]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ada = AdaBoost(DecisionTreeClassifier(max_depth = 1))\n",
    "ada.fit(np.array(X).reshape(-1, 1), np.array(Y), 3)\n",
    "print(ada.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用鸢尾花数据集进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_npz = np.load('iris.npz')\n",
    "data = iris_npz['data']\n",
    "X = iris_npz['X']\n",
    "Y = iris_npz['Y']\n",
    "# 转换成适合 AdaBoost 处理的标签\n",
    "Y[:50] = 1\n",
    "Y[50:] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRAIN, XTEST, YTRAIN, YTEST = train_test_split(X, Y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weaker 0 accuracy = 90.67%\n",
      "Weaker 1 accuracy = 78.67%\n",
      "Weaker 2 accuracy = 84.00%\n",
      "Weaker 3 accuracy = 66.67%\n",
      "Weaker 4 accuracy = 72.00%\n",
      "Weaker 5 accuracy = 86.67%\n",
      "Weaker 6 accuracy = 69.33%\n",
      "Weaker 7 accuracy = 52.00%\n",
      "Weaker 8 accuracy = 78.67%\n",
      "Weaker 9 accuracy = 86.67%\n",
      "\n",
      "AdaBoost accuracy = 100.00%, training completed!\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "ada = AdaBoost(DecisionTreeClassifier(max_depth = 1)) # 使用决策树桩作为弱分类器\n",
    "ada.fit(XTRAIN, YTRAIN, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.00%\n"
     ]
    }
   ],
   "source": [
    "results = ada.predict(XTEST)\n",
    "scores = (results == YTEST)\n",
    "print('Accuracy = {:3.2f}%'.format(Counter(scores)[True]/len(YTEST) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators = 10)\n",
    "clf.fit(XTRAIN, YTRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(XTEST, YTEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提升树模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostTree:\n",
    "    def __init__(self, base):\n",
    "        self.base = base # 弱回归器\n",
    "    \n",
    "    def fit(self, X, Y, max_step):\n",
    "        self.weaker = [] # 存放弱回归器\n",
    "        R = copy.deepcopy(Y) # 残差\n",
    "        for step in range(max_step): # 训练弱回归器\n",
    "            weaker = copy.deepcopy(self.base) # 生成一个新弱回归器\n",
    "            weaker.fit(X, R) # 训练弱回归器\n",
    "            results = weaker.predict(X)\n",
    "            R = R - results # 计算残差\n",
    "            self.weaker.append(weaker)\n",
    "            # 计算误差\n",
    "            f = np.sum(np.c_[[weaker.predict(X) for weaker in self.weaker]].T, axis = 1)\n",
    "            print('Step {}, square loss {}'.format(step, np.linalg.norm(f - Y)**2))\n",
    "        print('\\nBoosting tree training completed!')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.sum(np.c_[[weaker.predict(X) for weaker in self.weaker]].T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "Y = [5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05]\n",
    "XTEST = [1.2, 2.3, 3.4, 4.5, 5.6, 6.7, 7.8, 8.9, 9.5, 10.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, square loss 1.9300083333333338\n",
      "Step 1, square loss 0.800675\n",
      "Step 2, square loss 0.4780083333333336\n",
      "Step 3, square loss 0.3055592592592599\n",
      "Step 4, square loss 0.22891522633744946\n",
      "Step 5, square loss 0.1721780649862837\n",
      "\n",
      "Boosting tree training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "bt = BoostTree(DecisionTreeRegressor(max_depth = 1)) # 使用回归决策树桩作为弱回归器\n",
    "bt.fit(np.array(X).reshape(-1, 1), Y, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.63      , 5.63      , 5.81831019, 6.55164352, 6.81969907,\n",
       "       8.95016204, 8.95016204, 8.95016204, 8.95016204, 8.95016204])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.predict(np.array(XTEST).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 sklearn.ensemble.AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='square',\n",
       "                  n_estimators=6, random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "rsr = AdaBoostRegressor(loss = 'square', n_estimators = 6)\n",
    "rsr.fit(np.array(X).reshape(-1, 1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final square loss 0.05230000000000058\n"
     ]
    }
   ],
   "source": [
    "print('Final square loss {}'.format(np.linalg.norm(rsr.predict(np.array(X).\n",
    "reshape(-1, 1)) - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.63, 5.7 , 5.91, 6.4 , 7.05, 8.9 , 8.9 , 9.  , 9.  , 9.  ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsr.predict(np.array(XTEST).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=6,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "rsr = GradientBoostingRegressor(loss = 'ls', n_estimators = 6)\n",
    "rsr.fit(np.array(X).reshape(-1, 1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final square loss 5.424059630005812\n"
     ]
    }
   ],
   "source": [
    "print('Final square loss {}'.format(np.linalg.norm(rsr.predict(np.array(X).\n",
    "reshape(-1, 1)) - Y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.50762479, 6.54599735, 6.64125405, 6.89189235, 7.14105909,\n",
       "       8.05341449, 7.95970269, 8.10027039, 8.10027039, 8.12369834])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsr.predict(np.array(XTEST).reshape(-1, 1))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.063px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
