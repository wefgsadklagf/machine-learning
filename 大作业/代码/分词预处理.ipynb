{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_stop_words = {\n",
    "    \" \",    \"，\",    \"。\",    \"“\",    \"”\",    \"？\",    \"！\",    \"：\",    \"《\",    \"》\",    \"、\",    \"；\",    \"·\",    \"‘ \",    \"’\",    \"──\",    \"——\",    \",\",    \".\",    \"?\",    \"!\",    \"`\",    \"~\",    \"@\",    \"#\",    \"$\",    \"%\",    \"^\",    \"&\",    \"*\",    \"(\",    \")\",    \"-\",    \"_\",    \"+\",    \"=\",    \"[\",    \"]\",    \"{\",    \"}\",    '\"',    \"'\",    \"<\",    \">\",    \"\\\\\",    \"|\"    \"\\r\",    \"\\n\",    \"\\t\",    \"（\",    \"）\", \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"}\n",
    "\n",
    "def get_tags(src):\n",
    "    tags = []\n",
    "    if len(src) == 1:\n",
    "        tags = ['S']\n",
    "    elif len(src) == 2:\n",
    "        tags = ['B', 'E']\n",
    "    else:\n",
    "        m_num = len(src) - 2\n",
    "        tags.append('B')\n",
    "        for i in range(m_num):\n",
    "            tags.append('M')\n",
    "        tags.append('S')\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed\n"
     ]
    }
   ],
   "source": [
    "filename = './data/msr_training.txt'\n",
    "\n",
    "trans_mat =  {\"M\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"B\":{\"M\":0, 'B':0, \"S\":0, \"E\":0},\"S\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"E\":{\"M\":0., 'B':0, \"S\":0, \"E\":0}}\n",
    "emit_mat = {\"M\":{},\"B\":{},\"S\":{},\"E\":{}} # 发射矩阵\n",
    "init_vec = {\"M\":0., 'B':0, \"S\":0, \"E\":0} # 初始矩阵\n",
    "state_count = {\"M\":0., 'B':0, \"S\":0, \"E\":0}\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        words = lines[i].split(\"  \")\n",
    "        for index in range(len(words)):\n",
    "            if words[index] in seg_stop_words:\n",
    "                end = None\n",
    "                continue\n",
    "            tags = get_tags(words[index])\n",
    "#             print(words[index], tags)\n",
    "            for tag_index in range(len(tags)):\n",
    "                if(tag_index == len(tags) - 1):\n",
    "                    end = tags[tag_index]\n",
    "                # 初始矩阵\n",
    "                if tag_index == 0:\n",
    "                    init_vec[tags[tag_index]] += 1\n",
    "                # 发射矩阵\n",
    "                # print(words[index][tag_index], emit_mat[tags[tag_index]].keys())\n",
    "                if words[index] == \"\":\n",
    "                    continue\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    state_count[tags[tag_index]] += 1\n",
    "                else:\n",
    "                    state_count[tags[tag_index]] = 1\n",
    "                # 发射矩阵\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] += 1\n",
    "                else:\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] = 1\n",
    "                # 转移矩阵\n",
    "                if tag_index == 0:\n",
    "                    if end != None:\n",
    "                        trans_mat[end][tags[tag_index]] += 1\n",
    "                else:\n",
    "                    trans_mat[tags[tag_index-1]][tags[tag_index]] += 1\n",
    "data = {\"trans_mat\":trans_mat,  \"init_vec\":init_vec, \"emit_mat\":emit_mat,\"state_count\":state_count}  \n",
    "with open(\"./data\\d.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(data, fw, ensure_ascii=False)\n",
    "print(\"succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed\n"
     ]
    }
   ],
   "source": [
    "filename = './data/pku_training.txt'\n",
    "\n",
    "trans_mat =  {\"M\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"B\":{\"M\":0, 'B':0, \"S\":0, \"E\":0},\"S\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"E\":{\"M\":0., 'B':0, \"S\":0, \"E\":0}}\n",
    "emit_mat = {\"M\":{},\"B\":{},\"S\":{},\"E\":{}} # 发射矩阵\n",
    "init_vec = {\"M\":0., 'B':0, \"S\":0, \"E\":0} # 初始矩阵\n",
    "state_count = {\"M\":0., 'B':0, \"S\":0, \"E\":0}\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        words = lines[i].split(\"  \")\n",
    "        for index in range(len(words)):\n",
    "            if words[index] in seg_stop_words:\n",
    "                end = None\n",
    "                continue\n",
    "            tags = get_tags(words[index])\n",
    "#             print(words[index], tags)\n",
    "            for tag_index in range(len(tags)):\n",
    "                if(tag_index == len(tags) - 1):\n",
    "                    end = tags[tag_index]\n",
    "                # 初始矩阵\n",
    "                if tag_index == 0:\n",
    "                    init_vec[tags[tag_index]] += 1\n",
    "                # 发射矩阵\n",
    "                # print(words[index][tag_index], emit_mat[tags[tag_index]].keys())\n",
    "                if words[index] == \"\":\n",
    "                    continue\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    state_count[tags[tag_index]] += 1\n",
    "                else:\n",
    "                    state_count[tags[tag_index]] = 1\n",
    "                # 发射矩阵\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] += 1\n",
    "                else:\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] = 1\n",
    "                # 转移矩阵\n",
    "                if tag_index == 0:\n",
    "                    if end != None:\n",
    "                        trans_mat[end][tags[tag_index]] += 1\n",
    "                else:\n",
    "                    trans_mat[tags[tag_index-1]][tags[tag_index]] += 1\n",
    "\n",
    "data = {\"trans_mat\":trans_mat,  \"init_vec\":init_vec, \"emit_mat\":emit_mat,\"state_count\":state_count}  \n",
    "with open(\"./data\\dd.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(data, fw, ensure_ascii=False)\n",
    "print(\"succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed\n"
     ]
    }
   ],
   "source": [
    "Data_Filename = \"./data\\dict.txt\"\n",
    "\n",
    "trans_mat =  {\"M\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"B\":{\"M\":0, 'B':0, \"S\":0, \"E\":0},\"S\":{\"M\":0., 'B':0, \"S\":0, \"E\":0},\"E\":{\"M\":0., 'B':0, \"S\":0, \"E\":0}}\n",
    "emit_mat = {\"M\":{},\"B\":{},\"S\":{},\"E\":{}} # 发射矩阵\n",
    "init_vec = {\"M\":0., 'B':0, \"S\":0, \"E\":0} # 初始矩阵\n",
    "state_count = {\"M\":0., 'B':0, \"S\":0, \"E\":0}\n",
    "\n",
    "with open(Data_Filename, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        items = lines[i].split(\" \")\n",
    "        word = items[0]\n",
    "        count = int(items[1])\n",
    "        tags = get_tags(word)\n",
    "        # 发射矩阵\n",
    "        emit_mat['S'][word] = count\n",
    "        if len(tags) == 1:\n",
    "            state_count['S'] += count\n",
    "            init_vec[tags[0]] += count\n",
    "        else:\n",
    "            for tag_index in range(len(tags)):\n",
    "                if tag_index == 0:\n",
    "                    init_vec[tags[tag_index]] += count\n",
    "                    emit_mat[tags[tag_index]][word[tag_index]] = count\n",
    "                    state_count[tags[tag_index]] += count\n",
    "                else: \n",
    "                    emit_mat[tags[tag_index]][word[tag_index]] = count\n",
    "                    state_count[tags[tag_index]] += count\n",
    "                    trans_mat[tags[tag_index-1]][tags[tag_index]] += count\n",
    "data = {\"trans_mat\":trans_mat,  \"init_vec\":init_vec, \"emit_mat\":emit_mat,\"state_count\":state_count}  \n",
    "with open(\"./data\\ddd.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(data, fw, ensure_ascii=False)\n",
    "print(\"succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succeed\n"
     ]
    }
   ],
   "source": [
    "Data_Filename = \"./data\\ddd.json\"\n",
    "fr = open(Data_Filename, 'r', encoding='utf-8')\n",
    "txt = fr.read()\n",
    "model = json.loads(txt)\n",
    "trans_mat = model['trans_mat']\n",
    "emit_mat = model['emit_mat']\n",
    "init_vec = model['init_vec']\n",
    "state_count = model['state_count']\n",
    "fr.close()\n",
    "\n",
    "filename = './data/pku_training.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        words = lines[i].split(\"  \")\n",
    "        for index in range(len(words)):\n",
    "            if words[index] in seg_stop_words:\n",
    "                end = None\n",
    "                continue\n",
    "            tags = get_tags(words[index])\n",
    "#             print(words[index], tags)\n",
    "            for tag_index in range(len(tags)):\n",
    "                if(tag_index == len(tags) - 1):\n",
    "                    end = tags[tag_index]\n",
    "                # 初始矩阵\n",
    "                if tag_index == 0:\n",
    "                    init_vec[tags[tag_index]] += 1\n",
    "                # 发射矩阵\n",
    "                # print(words[index][tag_index], emit_mat[tags[tag_index]].keys())\n",
    "                if words[index] == \"\":\n",
    "                    continue\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    state_count[tags[tag_index]] += 1\n",
    "                else:\n",
    "                    state_count[tags[tag_index]] = 1\n",
    "                # 发射矩阵\n",
    "                if words[index][tag_index] in emit_mat[tags[tag_index]].keys():\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] += 1\n",
    "                else:\n",
    "                    emit_mat[tags[tag_index]][words[index][tag_index]] = 1\n",
    "                # 转移矩阵\n",
    "                if tag_index == 0:\n",
    "                    if end != None:\n",
    "                        trans_mat[end][tags[tag_index]] += 1\n",
    "                else:\n",
    "                    trans_mat[tags[tag_index-1]][tags[tag_index]] += 1\n",
    "data = {\"trans_mat\":trans_mat,  \"init_vec\":init_vec, \"emit_mat\":emit_mat,\"state_count\":state_count}  \n",
    "with open(\"./data\\dddd.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(data, fw, ensure_ascii=False)\n",
    "print(\"succeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
